CIFAR-10 normalization: mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.2435, 0.2616)
Augmentations used for TRAIN: RandomCrop(32, padding=4), RandomHorizontalFlip(p=0.5), ColorJitter(0.2/0.2/0.2/0.02), RandomErasingSquare(~2%)
VAL/TEST transforms: ToTensor + Normalize
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/vgg6_cifar/scripts/train_experiment.py:75: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.
  warnings.warn(warn_msg)
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/vgg6_cifar/engine/trainer.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
[Epoch 005] lr=0.10000 train_loss=1.4372 acc=0.4668 val_loss=3.4246 acc=0.1542
[Epoch 010] lr=0.10000 train_loss=1.1443 acc=0.5868 val_loss=1.7373 acc=0.3864
[Epoch 015] lr=0.10000 train_loss=1.0261 acc=0.6333 val_loss=2.2505 acc=0.3322
[Epoch 020] lr=0.10000 train_loss=0.9409 acc=0.6633 val_loss=1.5562 acc=0.4844
[Epoch 025] lr=0.10000 train_loss=0.9188 acc=0.6741 val_loss=6.3836 acc=0.1150
[Epoch 030] lr=0.10000 train_loss=0.8770 acc=0.6913 val_loss=2.7647 acc=0.3318
[Epoch 035] lr=0.10000 train_loss=0.8587 acc=0.6975 val_loss=3.6391 acc=0.2364
[Epoch 040] lr=0.10000 train_loss=0.8099 acc=0.7141 val_loss=5.8195 acc=0.1122
FINAL TEST: loss=1.4958  top1_acc=0.4989

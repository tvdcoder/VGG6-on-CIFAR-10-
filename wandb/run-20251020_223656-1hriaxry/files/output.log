CIFAR-10 normalization: mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.2435, 0.2616)
Augmentations used for TRAIN: RandomCrop(32, padding=4), RandomHorizontalFlip(p=0.5), ColorJitter(0.2/0.2/0.2/0.02), RandomErasingSquare(~2%)
VAL/TEST transforms: ToTensor + Normalize
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/vgg6_cifar/scripts/train_experiment.py:75: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.
  warnings.warn(warn_msg)
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/vgg6_cifar/engine/trainer.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
[Epoch 005] lr=0.10000 train_loss=0.9614 acc=0.6636 val_loss=0.9078 acc=0.6868
[Epoch 010] lr=0.10000 train_loss=0.6220 acc=0.7917 val_loss=0.6581 acc=0.7700
[Epoch 015] lr=0.10000 train_loss=0.4752 acc=0.8424 val_loss=0.5438 acc=0.8196
[Epoch 020] lr=0.10000 train_loss=0.3933 acc=0.8683 val_loss=0.5268 acc=0.8210
[Epoch 025] lr=0.10000 train_loss=0.3481 acc=0.8844 val_loss=0.5751 acc=0.8170
[Epoch 030] lr=0.10000 train_loss=0.3158 acc=0.8938 val_loss=0.6147 acc=0.8066
[Epoch 035] lr=0.10000 train_loss=0.2866 acc=0.9033 val_loss=0.4865 acc=0.8374
[Epoch 040] lr=0.10000 train_loss=0.2753 acc=0.9069 val_loss=0.5808 acc=0.8158
FINAL TEST: loss=0.4558  top1_acc=0.8548

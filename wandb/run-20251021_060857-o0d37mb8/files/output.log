CIFAR-10 normalization: mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.2435, 0.2616)
Augmentations used for TRAIN: RandomCrop(32, padding=4), RandomHorizontalFlip(p=0.5), ColorJitter(0.2/0.2/0.2/0.02), RandomErasingSquare(~2%)
VAL/TEST transforms: ToTensor + Normalize
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/vgg6_cifar/scripts/train_experiment.py:75: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.
  warnings.warn(warn_msg)
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/vgg6_cifar/engine/trainer.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
[Epoch 005] lr=0.01250 train_loss=1.3688 acc=0.4995 val_loss=1.2867 acc=0.5416
[Epoch 010] lr=0.01250 train_loss=0.9679 acc=0.6576 val_loss=0.9204 acc=0.6712
[Epoch 015] lr=0.01250 train_loss=0.7321 acc=0.7488 val_loss=0.8049 acc=0.7106
[Epoch 020] lr=0.01250 train_loss=0.5964 acc=0.7984 val_loss=0.6803 acc=0.7702
[Epoch 025] lr=0.01250 train_loss=0.4997 acc=0.8335 val_loss=0.5112 acc=0.8264
[Epoch 030] lr=0.01250 train_loss=0.4314 acc=0.8545 val_loss=0.5088 acc=0.8270
[Epoch 035] lr=0.01250 train_loss=0.3885 acc=0.8715 val_loss=0.4970 acc=0.8334
[Epoch 040] lr=0.01250 train_loss=0.3460 acc=0.8855 val_loss=0.5505 acc=0.8108
FINAL TEST: loss=0.4784  top1_acc=0.8381

CIFAR-10 normalization: mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.2435, 0.2616)
Augmentations used for TRAIN: RandomCrop(32, padding=4), RandomHorizontalFlip(p=0.5), ColorJitter(0.2/0.2/0.2/0.02), RandomErasingSquare(~2%)
VAL/TEST transforms: ToTensor + Normalize
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/vgg6_cifar/scripts/train_experiment.py:71: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.
  warnings.warn(warn_msg)
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/vgg6_cifar/engine/trainer.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
[Epoch 001] lr=0.02507 train_loss=1.5682 acc=0.4214 val_loss=1.3260 acc=0.5330
[Epoch 002] lr=0.02514 train_loss=1.1285 acc=0.5996 val_loss=0.9694 acc=0.6450
[Epoch 003] lr=0.02521 train_loss=0.9350 acc=0.6735 val_loss=0.8826 acc=0.6844
[Epoch 004] lr=0.02528 train_loss=0.8157 acc=0.7152 val_loss=0.7491 acc=0.7344
[Epoch 005] lr=0.02536 train_loss=0.7336 acc=0.7421 val_loss=0.7329 acc=0.7466
[Epoch 006] lr=0.02543 train_loss=0.6854 acc=0.7616 val_loss=0.6987 acc=0.7590
[Epoch 007] lr=0.02550 train_loss=0.6393 acc=0.7790 val_loss=0.6917 acc=0.7596
[Epoch 008] lr=0.02557 train_loss=0.6038 acc=0.7911 val_loss=0.6661 acc=0.7634
[Epoch 009] lr=0.02564 train_loss=0.5806 acc=0.8002 val_loss=0.5669 acc=0.7936
[Epoch 010] lr=0.02571 train_loss=0.5542 acc=0.8083 val_loss=0.5866 acc=0.7974
[Epoch 011] lr=0.02578 train_loss=0.5320 acc=0.8178 val_loss=0.6045 acc=0.7920
[Epoch 012] lr=0.02585 train_loss=0.5094 acc=0.8251 val_loss=0.5618 acc=0.8028
[Epoch 013] lr=0.02592 train_loss=0.4905 acc=0.8292 val_loss=0.5256 acc=0.8180
[Epoch 014] lr=0.02599 train_loss=0.4854 acc=0.8334 val_loss=0.5154 acc=0.8216

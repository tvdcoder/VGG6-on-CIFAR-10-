CIFAR-10 normalization: mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.2435, 0.2616)
Augmentations used for TRAIN: RandomCrop(32, padding=4), RandomHorizontalFlip(p=0.5), ColorJitter(0.2/0.2/0.2/0.02), RandomErasingSquare(~2%)
VAL/TEST transforms: ToTensor + Normalize
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/vgg6_cifar/scripts/train_experiment.py:75: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler(enabled=args.amp)
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/amp/grad_scaler.py:136: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.
  warnings.warn(warn_msg)
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/vgg6_cifar/engine/trainer.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/Users/santhoshtanay/Desktop/momeet/vgg6_cifar_full_bundle/.venv/lib/python3.13/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
[Epoch 005] lr=0.10000 train_loss=0.8225 acc=0.7185 val_loss=0.7901 acc=0.7212
[Epoch 010] lr=0.10000 train_loss=0.5485 acc=0.8143 val_loss=0.5516 acc=0.8038
[Epoch 015] lr=0.10000 train_loss=0.4338 acc=0.8525 val_loss=0.5334 acc=0.8172
[Epoch 020] lr=0.10000 train_loss=0.3588 acc=0.8787 val_loss=0.5493 acc=0.8156
[Epoch 025] lr=0.10000 train_loss=0.3145 acc=0.8925 val_loss=0.4178 acc=0.8586
[Epoch 030] lr=0.10000 train_loss=0.2758 acc=0.9043 val_loss=0.4266 acc=0.8564
[Epoch 035] lr=0.10000 train_loss=0.2548 acc=0.9113 val_loss=0.4253 acc=0.8542
[Epoch 040] lr=0.10000 train_loss=0.2381 acc=0.9181 val_loss=0.4218 acc=0.8610
FINAL TEST: loss=0.4001  top1_acc=0.8715
